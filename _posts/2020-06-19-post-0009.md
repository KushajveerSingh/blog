---
keywords: fastai
description: Random Walks, Memorization, Robust Learning, Monte Carlo
title: "STOC 2020: Session Notes"
toc: true
comments: true
author: Kushajveer Singh
categories: [notes, conference]
badges: false
nb_path: _notebooks/2020-06-19-post-0009.ipynb
layout: notebook
---

<!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-06-19-post-0009.ipynb
-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Session-3A---Walking-Randomly,-Massively,-and-Efficiently">Session 3A - Walking Randomly, Massively, and Efficiently<a class="anchor-link" href="#Session-3A---Walking-Randomly,-Massively,-and-Efficiently"> </a></h2><p>by Jakub Lacki, <strong>Slobodan Mitrovic</strong>, Krzysztofof Onak, Piotr Sankowski <a href="https://youtu.be/xoodhmjJ9Xs">video link</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Overview-of-work">Overview of work<a class="anchor-link" href="#Overview-of-work"> </a></h3><p>How to compute Random Walks? (in "a small" number of parallel steps)</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Random-Walks-in-Undirected-Graphs">Random Walks in Undirected Graphs<a class="anchor-link" href="#Random-Walks-in-Undirected-Graphs"> </a></h3><p>To generate a walk of length <code>L</code> from vertex <code>v</code> to <code>x</code>, we can follow the below procedure</p>
<ol>
<li>Computer a random walk of length <code>L/2</code> from $v\rightarrow w$ and random walk of length <code>L/2</code> from $w\rightarrow x$.</li>
<li>Stitch the two above random walks to get the random walk of length <code>L</code> from $v\rightarrow x$.</li>
</ol>
<p>We can repeat the above procedure recursively by computing random walks of length L/2, L/2, ...</p>
<p>Now the problem is how many walks will pass through <code>w</code> (it follows stationary distribution).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Conclusion">Conclusion<a class="anchor-link" href="#Conclusion"> </a></h3><p>Compute independent random walk of length L from each vertex</p>
<ul>
<li>in poly log L steps<ul>
<li>undirected: $O(\log L)$ rounds</li>
<li>directed: $O(\log^2\log n+\log^21/\epsilon)$</li>
</ul>
</li>
<li>using $O(m^{1+o(1)})$ memory</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Session-7C---Does-Learning-Require-Memorization?-A-Short-Tale-about-a-Long-Tail">Session 7C - Does Learning Require Memorization? A Short Tale about a Long Tail<a class="anchor-link" href="#Session-7C---Does-Learning-Require-Memorization?-A-Short-Tale-about-a-Long-Tail"> </a></h2><p>by <strong>Vitaly Feldman</strong> <a href="https://youtu.be/sV59uoWJRnk">video link</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Overview-of-problem">Overview of problem<a class="anchor-link" href="#Overview-of-problem"> </a></h3><p>For state-of-the-art deep learning algorithms on text/images, we see this pattern</p>
<ul>
<li>Training set error: 0-1%</li>
<li>(Typical) test set error: 10-30%</li>
</ul>
<p>This means the data distribution has a large number of points that the data distribution could not classify accurately. These misclassified points are generally outliers and misclassified labels. This same thing is true for training dataset also, which means the model is memorizing the labels for some inputs, otherwise it would not be able to achieve smaller training error rates.</p>
<p>An example was shown where Inception model was trained on random Imagenet labels, and yet it achieved 9% training error. Which means the model was memorizing the labels, as it is not possible to learn from random labels.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Defining-label-memorization">Defining label memorization<a class="anchor-link" href="#Defining-label-memorization"> </a></h3><p>$mem(A,S,i)$ where</p>
<ul>
<li>A = learning algorithm</li>
<li>S = dataset</li>
<li>i = $i^{th}$ example in dataset</li>
</ul>
<p>Memorization is defined as the difference between output of softmax of the model, first when <em>i</em> is part of training set and second when <em>i</em> is part of test set i.e.
{% raw %}
$$mem(A,S,i)=Pr(i\ in\ train)-Pr(i\ in\ test)$$
{% endraw %}</p>
<p>We say an example is memorized if the above value is greater than some threshold (say 0.5).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include tip.html content='Memorization can be thought of as the difference between training and test error (i.e. generalization gap). If this value is large, we can say the model memorized more.' %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Why-memorization-is-important?">Why memorization is important?<a class="anchor-link" href="#Why-memorization-is-important?"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="/blog/images/copied_from_nb/images/post_009/01.jpeg" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The four pictures in the training set are not much useful for learning what is a truck. Because in real life we would not see trucks like these. But if we memorize the first example, we get better result for the corresponding test image shown and same for the third image.</p>
<p>So memorization is essential in this case to perform better on the test set. But the problem is our model memorizes all the four images in the training set (some of which don't even benefit on the test set). <strong>And this is the reason why we see a difference in the training set and test set error rates</strong>. The model is memorizing useless examples.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include note.html content='In the above example it is assumed that test set is the real representation of real life i.e. we are not arguing that images in test set are not even real life images of truck. This is a separate problem of not making good test sets' %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So memorization is useful in some cases and in worst case is bad.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Conclusion">Conclusion<a class="anchor-link" href="#Conclusion"> </a></h3><p>Label memorization is necessary for optimal generalization on long-tailed data distributions (not algorithm-specific).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Session-7C---Efficiently-Learning-Structured-Distributions-from-Unstructured-Batches">Session 7C - Efficiently Learning Structured Distributions from Unstructured Batches<a class="anchor-link" href="#Session-7C---Efficiently-Learning-Structured-Distributions-from-Unstructured-Batches"> </a></h2><p>by <strong>Sitan Chen</strong>, Jerry Li, Ankur Moitra <a href="https://youtu.be/pKXj8a0ZZIY">video link</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Overview-of-problem">Overview of problem<a class="anchor-link" href="#Overview-of-problem"> </a></h3><p>Inspired by <strong>Robust Learning</strong>. Can we design algorithms that can tolerate a constant fraction of corruptions in the data? These corruptions arise in</p>
<ul>
<li>adversarial examples</li>
<li>data poisoning attacks on recommender systems</li>
<li>malware classifiers</li>
</ul>
<p>For this session, we deal with the problem where the data came from some crowdsource fashion. Like spell check app for mobile. We want to learn the distribution over misspellings of particular word. (This distribution is a discrete probability distribution over some words).</p>
<p>We have a central server where we collect the data from multiple users and aggregate the data to train our model. Now what if a constant fraction of users give adversarially chosen samples, to skew the model. We cannot distinguish between these adversarial and non-adversarial users.</p>
<p>We can only assume that as the number of batches increase for every user (a user will be sending multiple words to the server), the added redundancy will allow you to drive this error smaller and smaller.</p>
<p>In practical usage every user would have access to a some subset of the main distribution (if a person is interested in music, the words entered by him would resemble close to music, which will be different from a deep learning researcher). So our model should be able to tolerate these deviations from user to user (<strong>Federated Learning</strong>).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Session-8B---How-to-lose-at-Monte-Carlo:-a-simple-dynamical-system">Session 8B - How to lose at Monte Carlo: a simple dynamical system<a class="anchor-link" href="#Session-8B---How-to-lose-at-Monte-Carlo:-a-simple-dynamical-system"> </a></h2><p>by <strong>C.Rojas</strong>, <strong>M.Yampolsky</strong> <a href="https://youtu.be/92Hnb_W3kcI">video link</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In real life, all of the systems are non-deterministic because even the simplest model exhibit chaotic behavior (weather prediction is an example of this). Even the smallest errors in the calculation will blow up very fast so deterministic predictions are not possible.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Monte-Carlo-method(Non-deterministic-approach)">Monte Carlo method(Non-deterministic approach)<a class="anchor-link" href="#Monte-Carlo-method(Non-deterministic-approach)"> </a></h3><ol>
<li>Throw random darts to select a large number of initial values</li>
<li>Run the simulation for the desired duration for each of them; then statistically average the outcomes.</li>
<li>These averages are expected to reflect the true trajectory of the system.</li>
</ol>

</div>
</div>
</div>
</div>
 

