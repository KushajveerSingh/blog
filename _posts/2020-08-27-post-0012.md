---
keywords: fastai
description: Imagenet
title: "ImageNet Dataset Advancements"
toc: true
comments: true
author: Kushajveer Singh
categories: [discussion]
badges: true
nb_path: _notebooks/2020-08-27-post-0012.ipynb
layout: notebook
---

<!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-08-27-post-0012.ipynb
-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="References">References<a class="anchor-link" href="#References"> </a></h2><ul>
<li>WordNet: a lexical database for English <a href="https://dl.acm.org/doi/10.1145/219717.219748">link</a></li>
<li>ImageNet: A large-scale hierarchical image database <a href="https://ieeexplore.ieee.org/document/5206848">link</a></li>
<li>ImageNet Large Scale Visual Recognition Challenge <a href="https://arxiv.org/abs/1409.0575">link</a></li>
<li></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="ImageNet-database">ImageNet database<a class="anchor-link" href="#ImageNet-database"> </a></h2><p><a href="https://ieeexplore.ieee.org/document/5206848">paper</a></p>
<p>Quoting from <a href="https://arxiv.org/abs/1409.0575">ILSVRC paper</a></p>
<blockquote><p>ImageNet populates 21,841 synsets of WordNet with an average of 650 manually verified and full resolution images. As a result, ImageNet contains 14,197,122 annotated images organized by the semantic hierarchy of WordNet (as of August 2014).</p>
</blockquote>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="ImageNet-1k-dataset">ImageNet-1k dataset<a class="anchor-link" href="#ImageNet-1k-dataset"> </a></h2><p><a href="https://arxiv.org/abs/1409.0575">paper</a>, <a href="http://www.image-net.org/challenges/LSVRC/">website</a></p>
<p>The <strong>ILSVRC</strong> (ImageNet Large Scale Visual Recognition Challenge) ran from 2010-2017. This challenge provided the teams with a subset of ImageNet database, called ILSVRC-2012 or ImageNet-1k or ImageNet (I think ILSVRC-2012 is the correct name, but people also refer to this dataset by the later two names).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include note.html content='In this post I am only referring to <em>Image classification</em> task.' %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Dataset-creation-process">Dataset creation process<a class="anchor-link" href="#Dataset-creation-process"> </a></h3><ol>
<li><p><strong>Selecting categories</strong>:- The 1000 categories were manually (based on heuristics related to WordNet hierarchy). Also, to include fine-grained classification in the dataset the authors included 120 categories of dog breeds (this is why ImageNet models generally dream about dogs).</p>
</li>
<li><p><strong>Selecting candidate images</strong>:- Taken directly from ImageNet database. They basically did search queries for each category (synset) on several image search engines. The queries were also translated to Chinese, Spanish, Dutch and Italian to increase the diversity of the images.</p>
</li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include important.html content='Step 2 introduces the problem of inaccurate annotations because we don&#8217;t know whether the search engines are correct or not.' %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ol>
<li><strong>Annotating images</strong>:- Amazon Mechanical Turk (AMT) was used to label the images. Each user was a given a set of candidate images and the definition of the target category (synset). The users were then asked to verify if the image contained the category. There was also a quality control system setup which you can read in the paper. </li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Proble">Proble<a class="anchor-link" href="#Proble"> </a></h3>
</div>
</div>
</div>
</div>
 

