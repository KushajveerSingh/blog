{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"STOC 2020: Session Notes\"\n",
    "> Random Walks, Memorization, Robust Learning, Monte Carlo\n",
    "- toc: true\n",
    "- comments: true\n",
    "- author: Kushajveer Singh\n",
    "- categories: [notes]\n",
    "- badges: false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Session 3A - Walking Randomly, Massively, and Efficiently\n",
    "by Jakub Lacki, **Slobodan Mitrovic**, Krzysztofof Onak, Piotr Sankowski [video link](https://youtu.be/xoodhmjJ9Xs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Overview of work\n",
    "How to compute Random Walks? (in \"a small\" number of parallel steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Random Walks in Undirected Graphs\n",
    "To generate a walk of length `L` from vertex `v` to `x`, we can follow the below procedure\n",
    "1. Computer a random walk of length `L/2` from $v\\rightarrow w$ and random walk of length `L/2` from $w\\rightarrow x$.\n",
    "2. Stitch the two above random walks to get the random walk of length `L` from $v\\rightarrow x$.\n",
    "\n",
    "We can repeat the above procedure recursively by computing random walks of length L/2, L/2, ...\n",
    "\n",
    "Now the problem is how many walks will pass through `w` (it follows stationary distribution)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Conclusion\n",
    "Compute independent random walk of length L from each vertex\n",
    "- in poly log L steps\n",
    "    * undirected: $O(\\log L)$ rounds\n",
    "    * directed: $O(\\log^2\\log n+\\log^21/\\epsilon)$\n",
    "- using $O(m^{1+o(1)})$ memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session 7C - Does Learning Require Memorization? A Short Tale about a Long Tail\n",
    "by **Vitaly Feldman** [video link](https://youtu.be/sV59uoWJRnk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of problem\n",
    "For state-of-the-art deep learning algorithms on text/images, we see this pattern\n",
    "* Training set error: 0-1%\n",
    "* (Typical) test set error: 10-30%\n",
    "\n",
    "This means the data distribution has a large number of points that the data distribution could not classify accurately. These misclassified points are generally outliers and misclassified labels. This same thing is true for training dataset also, which means the model is memorizing the labels for some inputs, otherwise it would not be able to achieve smaller training error rates.\n",
    "\n",
    "An example was shown where Inception model was trained on random Imagenet labels, and yet it achieved 9% training error. Which means the model was memorizing the labels, as it is not possible to learn from random labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining label memorization\n",
    "$mem(A,S,i)$ where \n",
    "- A = learning algorithm\n",
    "- S = dataset\n",
    "- i = $i^{th}$ example in dataset\n",
    "\n",
    "Memorization is defined as the difference between output of softmax of the model, first when *i* is part of training set and second when *i* is part of test set i.e.\n",
    "$$mem(A,S,i)=Pr(i\\ in\\ train)-Pr(i\\ in\\ test)$$\n",
    "\n",
    "We say an example is memorized if the above value is greater than some threshold (say 0.5)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Tip: Memorization can be thought of as the difference between training and test error (i.e. generalization gap). If this value is large, we can say the model memorized more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why memorization is important?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/post_009/01.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The four pictures in the training set are not much useful for learning what is a truck. Because in real life we would not see trucks like these. But if we memorize the first example, we get better result for the corresponding test image shown and same for the third image.\n",
    "\n",
    "So memorization is essential in this case to perform better on the test set. But the problem is our model memorizes all the four images in the training set (some of which don't even benefit on the test set). **And this is the reason why we see a difference in the training set and test set error rates**. The model is memorizing useless examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: In the above example it is assumed that test set is the real representation of real life i.e. we are not arguing that images in test set are not even real life images of truck. This is a separate problem of not making good test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So memorization is useful in some cases and in worst case is bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Label memorization is necessary for optimal generalization on long-tailed data distributions (not algorithm-specific)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Session 7C - Efficiently Learning Structured Distributions from Unstructured Batches\n",
    "by **Sitan Chen**, Jerry Li, Ankur Moitra [video link](https://youtu.be/pKXj8a0ZZIY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Overview of problem\n",
    "Inspired by **Robust Learning**. Can we design algorithms that can tolerate a constant fraction of corruptions in the data? These corruptions arise in \n",
    "- adversarial examples\n",
    "- data poisoning attacks on recommender systems\n",
    "- malware classifiers\n",
    "\n",
    "For this session, we deal with the problem where the data came from some crowdsource fashion. Like spell check app for mobile. We want to learn the distribution over misspellings of particular word. (This distribution is a discrete probability distribution over some words).\n",
    "\n",
    "We have a central server where we collect the data from multiple users and aggregate the data to train our model. Now what if a constant fraction of users give adversarially chosen samples, to skew the model. We cannot distinguish between these adversarial and non-adversarial users.\n",
    "\n",
    "We can only assume that as the number of batches increase for every user (a user will be sending multiple words to the server), the added redundancy will allow you to drive this error smaller and smaller.\n",
    "\n",
    "In practical usage every user would have access to a some subset of the main distribution (if a person is interested in music, the words entered by him would resemble close to music, which will be different from a deep learning researcher). So our model should be able to tolerate these deviations from user to user (**Federated Learning**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Session 8B - How to lose at Monte Carlo: a simple dynamical system\n",
    "by **C.Rojas**, **M.Yampolsky** [video link](https://youtu.be/92Hnb_W3kcI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In real life, all of the systems are non-deterministic because even the simplest model exhibit chaotic behavior (weather prediction is an example of this). Even the smallest errors in the calculation will blow up very fast so deterministic predictions are not possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Monte Carlo method(Non-deterministic approach)\n",
    "1. Throw random darts to select a large number of initial values\n",
    "2. Run the simulation for the desired duration for each of them; then statistically average the outcomes.\n",
    "3. These averages are expected to reflect the true trajectory of the system."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": "20",
    "lenType": "25",
    "lenVar": "50"
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
