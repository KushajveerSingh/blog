{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"fastai Data API from Foundations\"\n",
    "> TODO\n",
    "- toc: true\n",
    "- comments: true\n",
    "- author: Kushajveer Singh\n",
    "- categories: [notes]\n",
    "- badges: true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handles all the necessary imports\n",
    "from fastai.vision.all import *\n",
    "from fastai.callback.fp16 import to_fp16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get dataset\n",
    "For this post I use [Imagewoof](https://github.com/fastai/imagenette) dataset. There is nothing special here. It is an ImageNet style dataset and will provide a basis for the post."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Tip: In fastai if you cannot create a DataLoader, using a `csv` file is the best option. Define a `label` column and a `valid` column and it will just work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('train'),Path('val')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path('/home/kushaj/Desktop/Data/imagewoof2/')\n",
    "Path.BASE_PATH = path\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34;42m/home/kushaj/Desktop/Data/imagewoof2\u001b[00m\r\n",
      "├── \u001b[34;42mtrain\u001b[00m\r\n",
      "│   ├── \u001b[34;42mn02086240\u001b[00m\r\n",
      "│   ├── \u001b[34;42mn02087394\u001b[00m\r\n",
      "│   ├── \u001b[34;42mn02088364\u001b[00m\r\n",
      "│   ├── \u001b[34;42mn02089973\u001b[00m\r\n",
      "│   ├── \u001b[34;42mn02093754\u001b[00m\r\n",
      "│   ├── \u001b[34;42mn02096294\u001b[00m\r\n",
      "│   ├── \u001b[34;42mn02099601\u001b[00m\r\n",
      "│   ├── \u001b[34;42mn02105641\u001b[00m\r\n",
      "│   ├── \u001b[34;42mn02111889\u001b[00m\r\n",
      "│   └── \u001b[34;42mn02115641\u001b[00m\r\n",
      "└── \u001b[34;42mval\u001b[00m\r\n",
      "    ├── \u001b[34;42mn02086240\u001b[00m\r\n",
      "    ├── \u001b[34;42mn02087394\u001b[00m\r\n",
      "    ├── \u001b[34;42mn02088364\u001b[00m\r\n",
      "    ├── \u001b[34;42mn02089973\u001b[00m\r\n",
      "    ├── \u001b[34;42mn02093754\u001b[00m\r\n",
      "    ├── \u001b[34;42mn02096294\u001b[00m\r\n",
      "    ├── \u001b[34;42mn02099601\u001b[00m\r\n",
      "    ├── \u001b[34;42mn02105641\u001b[00m\r\n",
      "    ├── \u001b[34;42mn02111889\u001b[00m\r\n",
      "    └── \u001b[34;42mn02115641\u001b[00m\r\n",
      "\r\n",
      "22 directories, 0 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree {path} -L 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch `Dataset` class\n",
    "The base class to get items from the dataset. It is an instance of `torch.utils.data.Dataset`. fastai does not do anything special here. The same dataset class used in PyTorch can be used here.\n",
    "\n",
    "Let's start by defining the `Dataset` class for training and validation dataset. What do we need this class to do?\n",
    "\n",
    "It should get the name of image files. And that is it. The reason being the `DataLoader` class in fastai is very powerful (as we will soon see). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: To avoid messing up with fastai imports I use a underscore (\\_) in front of class names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, path=None): self.items = get_image_files(path)\n",
    "    def __len__(self)            : return len(self.items)\n",
    "    def __getitem__(self, i)     : return self.items[i]\n",
    "    \n",
    "dataset = {\n",
    "    'train': _Dataset(path/'train'),\n",
    "    'valid': _Dataset(path/'val'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9025, 3929)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset['train']), len(dataset['valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('train/n02111889/n02111889_11223.JPEG')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create `DataLoader`\n",
    "The base dataloader class that is defined in `fastai.data.load.DataLoader` forms the basis of fastai DataBlock API.\n",
    "\n",
    "Please refer to my previous post [Deep dive into fastai DataLoader methods](https://kushajveersingh.github.io/blog/notes/2020/09/05/post-0013.html) which provides a 2 minute summary of all the important methods of `DataLoader` class.\n",
    "\n",
    "From this point I assume you are comfortable with the methods available in `DataLoader` class and in what order they operate.\n",
    "\n",
    "Now let's start creating our `DataLoader`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get (image, label) tuple from filename\n",
    "This can be done using `after_item`. We need to read the image from disk and resize to a fixed size (224,224 for this example) and extract label of the image. For the labels, I manually create a dictionary to map folder name to integer.\n",
    "\n",
    "At this point we are still limiting ourselves by not using `Transform`s. We will use them in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {\n",
    "    'n02086240':0,\n",
    "    'n02087394':1,\n",
    "    'n02088364':2,\n",
    "    'n02089973':3,\n",
    "    'n02093754':4,\n",
    "    'n02096294':5,\n",
    "    'n02099601':6,\n",
    "    'n02105641':7,\n",
    "    'n02111889':8,\n",
    "    'n02115641':9,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def after_item(item):\n",
    "    # `item` here is dataset[idx] i.e. image file path\n",
    "    image = image2tensor(load_image(item, mode='RGB').resize((224,224)))\n",
    "    label = vocab[item.parent.name]\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[103, 105, 107,  ...,  85,  86,  89],\n",
       "          [105, 105, 105,  ...,  81,  78,  81],\n",
       "          [109, 109, 109,  ...,  85,  83,  83],\n",
       "          ...,\n",
       "          [ 50,  44,  39,  ...,  70,  66,  66],\n",
       "          [ 47,  51,  57,  ...,  63,  60,  70],\n",
       "          [ 43,  49,  45,  ...,  58,  60,  56]],\n",
       " \n",
       "         [[ 77,  79,  82,  ...,  53,  53,  53],\n",
       "          [ 78,  78,  80,  ...,  48,  48,  49],\n",
       "          [ 80,  80,  82,  ...,  49,  48,  48],\n",
       "          ...,\n",
       "          [122, 113, 102,  ..., 142, 137, 137],\n",
       "          [106, 116, 132,  ..., 136, 137, 139],\n",
       "          [ 85, 104,  98,  ..., 134, 136, 137]],\n",
       " \n",
       "         [[ 55,  57,  59,  ...,  38,  34,  32],\n",
       "          [ 55,  56,  56,  ...,  34,  31,  33],\n",
       "          [ 61,  61,  63,  ...,  32,  32,  34],\n",
       "          ...,\n",
       "          [118, 107,  99,  ..., 148, 145, 144],\n",
       "          [104, 113, 130,  ..., 142, 143, 146],\n",
       "          [ 69,  90,  91,  ..., 140, 143, 144]]], dtype=torch.uint8),\n",
       " 8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "after_item(dataset['train'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply some transforms\n",
    "This is where power of fastai comes into play. We can define the transforms to apply on CPU or on a complete batch on the GPU. `after_item` can also be considered a form of transform. \n",
    "\n",
    "To apply transforms on the complete batch on the GPU we use `after_batch`. For our example, we need to convert the image tensor to float and then normalize the tensor using imagenet mean and std."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def after_batch(b):\n",
    "    # `b` is a tuple of (image, label) \n",
    "    # `image` of shape [batch_size, num_channels, height, width]\n",
    "    # `label` of shape [batch_size]\n",
    "    device = torch.device('cuda')\n",
    "    b = to_device(b, device)\n",
    "    imgs, lbls = b\n",
    "    \n",
    "    # convert `imgs` to float\n",
    "    imgs = imgs.div(255.)\n",
    "    \n",
    "    # normalize data\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406], device=device).view(1,3,1,1)\n",
    "    std  = torch.tensor([0.229, 0.224, 0.225], device=device).view(1,3,1,1)\n",
    "    imgs = (imgs - mean) / std\n",
    "    \n",
    "    return imgs,lbls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create `DataLoader`\n",
    "Now we are ready to create a `DataLoader` for training and validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(dataset, shuffle):\n",
    "    return DataLoader(dataset,\n",
    "                      bs=64,\n",
    "                      num_workers=12,\n",
    "                      shuffle=True,\n",
    "                      after_item=after_item,\n",
    "                      after_batch=after_batch)\n",
    "\n",
    "dl = {\n",
    "    'train': get_dataloader(dataset['train'], shuffle=True),\n",
    "    'valid': get_dataloader(dataset['valid'], shuffle=False),\n",
    "}\n",
    "\n",
    "dls = DataLoaders(dl['train'], dl['valid'], device=torch.device('cuda'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataLoaders` is just a wrapper around a list of `DataLoader`s.\n",
    "\n",
    "And that is it. Now we can create a learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, \n",
    "                xresnet18(), \n",
    "                loss_func=CrossEntropyLossFlat(),\n",
    "                pretrained=False, \n",
    "                metrics=[accuracy]).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.597425</td>\n",
       "      <td>2.156052</td>\n",
       "      <td>0.234665</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.891093</td>\n",
       "      <td>1.834174</td>\n",
       "      <td>0.359888</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.618509</td>\n",
       "      <td>1.609872</td>\n",
       "      <td>0.434716</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
