<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Exploring the issue of depth in GNNs and exploring ways of solving it | Kushajveer Singh</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Exploring the issue of depth in GNNs and exploring ways of solving it" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="The post starts by exploring the question is depth a problem, then tries to find the reasons why depth is a problem and then the SOTA methods are discussed for solving this issue. Code for all experiments is available." />
<meta property="og:description" content="The post starts by exploring the question is depth a problem, then tries to find the reasons why depth is a problem and then the SOTA methods are discussed for solving this issue. Code for all experiments is available." />
<link rel="canonical" href="https://kushajveersingh.github.io/blog/graph/2021/03/04/post-0014.html" />
<meta property="og:url" content="https://kushajveersingh.github.io/blog/graph/2021/03/04/post-0014.html" />
<meta property="og:site_name" content="Kushajveer Singh" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-03-04T00:00:00-06:00" />
<script type="application/ld+json">
{"headline":"Exploring the issue of depth in GNNs and exploring ways of solving it","url":"https://kushajveersingh.github.io/blog/graph/2021/03/04/post-0014.html","dateModified":"2021-03-04T00:00:00-06:00","datePublished":"2021-03-04T00:00:00-06:00","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://kushajveersingh.github.io/blog/graph/2021/03/04/post-0014.html"},"description":"The post starts by exploring the question is depth a problem, then tries to find the reasons why depth is a problem and then the SOTA methods are discussed for solving this issue. Code for all experiments is available.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://kushajveersingh.github.io/blog/feed.xml" title="Kushajveer Singh" /><!-- the google_analytics_id gets auto inserted from the config file -->



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-123402359-3"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-123402359-3');
</script>


<link rel="shortcut icon" type="image/x-icon" href="/blog/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/blog/">Kushajveer Singh</a></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Exploring the issue of depth in GNNs and exploring ways of solving it</h1><p class="page-description">The post starts by exploring the question is depth a problem, then tries to find the reasons why depth is a problem and then the SOTA methods are discussed for solving this issue. Code for all experiments is available.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-03-04T00:00:00-06:00" itemprop="datePublished">
        Mar 4, 2021
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      2 min read
    
</span></p>

    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#deep-graph-neural-networks">(Deep) Graph Neural Networks</a></li>
<li class="toc-entry toc-h2"><a href="#gradient-vanishing">Gradient vanishing</a></li>
</ul><hr>
<ul>
  <li>[1] <a href="https://arxiv.org/abs/1704.01212">Neural Message Passing for Quantum Chemistry</a>
</li>
  <li>[2] <a href="https://arxiv.org/abs/1609.02907">Semi-Supervised Classification with Graph Convolutional Networks</a>
<a href="https://github.com/KushajveerSingh/gnn_depth">github</a>
</li>
</ul>

<blockquote>
  <p>The code for all the experiments is available on <a href="https://github.com/KushajveerSingh/gnn_depth">github</a>. README contains all the details on how to reproduce everything in the blog. For easier access, I will refer to the *.py files in the blog whereever necessary. The code uses <a href="https://github.com/rusty1s/pytorch_geometric">PyTorch Geometric</a> and <a href="https://seaborn.pydata.org/">Seaborn</a>.</p>
</blockquote>

<p>Graph neural networks (GNNs) have shown to be very useful for learning graph node representations over graph-structured data. The GNNs are trained using neural message passing framework [1] and Graph Convolutional Network (GCN) [2] is one of the most widely used GNN architecture. GNN architectures is the focus of my next blog. So for this post, I will use GCN for all the analysis.</p>

<p>So let’s start.</p>

<h2 id="deep-graph-neural-networks">
<a class="anchor" href="#deep-graph-neural-networks" aria-hidden="true"><span class="octicon octicon-link"></span></a>(Deep) Graph Neural Networks</h2>

<p>Deep learning is known for training very deep models (the word <em>deep</em> is in the name). So training deep GNNs should be a no brainer to get better accuracy.</p>

<p>Let’s explore this idea a bit. Below I show the results of training a {2,4,8,16,32,64}-Layer GCN on Cora dataset.</p>

<p><img src="/blog/images/post_0014/00.png" alt="" title="Figure 1: Performance degradation of GCNs is shown, where the accuracy of a deep GCN model drops by a large amount as depth increases."></p>

<blockquote>
  <p>Note: Use <code class="language-plaintext highlighter-rouge">python 01_deep_gcn.py</code> to reproduce results of Figure 1.</p>
</blockquote>

<p>The results are a complete opposite of what deep learning is famous for. So why did deeper models not train well?</p>

<p>The most reasons are gradient vanishing and overfitting due to a large number of parameters.</p>

<h2 id="gradient-vanishing">
<a class="anchor" href="#gradient-vanishing" aria-hidden="true"><span class="octicon octicon-link"></span></a>Gradient vanishing</h2>

<p>Gradient vanishing occurs in deep models when small gradients (less than 1) keep multiplying. We can confirm this by checking the spread of the gradients over time ($mean \pm std$). Figure 2, shows the gradients of the second layer of a 32-Layer GCN model during training.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Epoch</th>
      <th style="text-align: center">Mean</th>
      <th style="text-align: center">Std</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">0</td>
      <td style="text-align: center">-6.438882849124639e-08</td>
      <td style="text-align: center">7.142710387597617e-07</td>
    </tr>
    <tr>
      <td style="text-align: center">50</td>
      <td style="text-align: center">-2.276356322406317e-14</td>
      <td style="text-align: center">9.411642472312298e-13</td>
    </tr>
    <tr>
      <td style="text-align: center">100</td>
      <td style="text-align: center">6.48658677992151e-25</td>
      <td style="text-align: center">0.0</td>
    </tr>
    <tr>
      <td style="text-align: center">150</td>
      <td style="text-align: center">-3.384510150852408e-33</td>
      <td style="text-align: center">0.0</td>
    </tr>
    <tr>
      <td style="text-align: center">200</td>
      <td style="text-align: center">4.707241801359926e-41</td>
      <td style="text-align: center">0.0</td>
    </tr>
    <tr>
      <td style="text-align: center">250</td>
      <td style="text-align: center">0.0</td>
      <td style="text-align: center">0.0</td>
    </tr>
    <tr>
      <td style="text-align: center">300</td>
      <td style="text-align: center">0.0</td>
      <td style="text-align: center">0.0</td>
    </tr>
    <tr>
      <td style="text-align: center">350</td>
      <td style="text-align: center">0.0</td>
      <td style="text-align: center">0.0</td>
    </tr>
    <tr>
      <td style="text-align: center">400</td>
      <td style="text-align: center">0.0</td>
      <td style="text-align: center">0.0</td>
    </tr>
  </tbody>
</table>

<blockquote>
  <p>Note: Use <code class="language-plaintext highlighter-rouge">python 02_check_gradients.py</code> to reproduce results of above table.</p>
</blockquote>

<p>We can see that gradients quickly vanish to 0, which is bad. In computer vision to solve this problem, the idea of residual (shortcut) connections was developed. The idea of residual connections is to add the original input to the output of a function, as shown below</p>

<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>o</mi><mi>r</mi><mi>i</mi><mi>g</mi><mi mathvariant="normal">_</mi><mi>x</mi><mo>=</mo><mi>x</mi></mrow><annotation encoding="application/x-tex">orig\_x = x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9695em;vertical-align:-0.31em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">or</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span></span>

<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>x</mi><mo>=</mo><mi>f</mi><mi>u</mi><mi>n</mi><mi>c</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">x = func(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">u</span><span class="mord mathnormal">n</span><span class="mord mathnormal">c</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span></span>

<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>x</mi><mo>=</mo><mi>o</mi><mi>r</mi><mi>i</mi><mi>g</mi><mi mathvariant="normal">_</mi><mi>x</mi><mo>+</mo><mi>x</mi></mrow><annotation encoding="application/x-tex">x = orig\_x + x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.9695em;vertical-align:-0.31em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">or</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span></span>

<p>Roughly, during backpropagation 1 is added to the gradients of $x$ which prevents vanishing gradients (as gradients now become &gt; 1).</p>

<p>Now let’s add residual connections to the GCN models and check if the accuracy improves.</p>

<blockquote>
  <p>Note: Use <code class="language-plaintext highlighter-rouge">python 03_deep_gcn_with_residual.py</code> to reproduce results of Figure 2 and above table.</p>
</blockquote>

  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="KushajveerSingh/blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/blog/graph/2021/03/04/post-0014.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Software Engineer working in Full Stack Development, Computer Vision, and Graph Machine Learning.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/KushajveerSingh" target="_blank" title="KushajveerSingh"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/Kkushaj" target="_blank" title="Kkushaj"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
